{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import cvzone\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import json\n",
    "import os # list directories\n",
    "from datetime import datetime\n",
    "\n",
    "# GETTING INFO FROM DATABASE\n",
    "# DB CONNECTION\n",
    "con = sqlite3.connect(\n",
    "    'E:/OneDrive - UNIVERSIDAD DE HUELVA\\TFG\\VisionParkWeb-main\\VisionParkWeb\\VisionParkWeb\\db.sqlite3', timeout=10)\n",
    "\n",
    "\n",
    "def fetch_parkings(con)->list:\n",
    "    cursorObj = con.cursor()\n",
    "    cursorObj.execute('SELECT id,name FROM manageParking_parking')\n",
    "\n",
    "    return cursorObj.fetchall()\n",
    "\n",
    "\n",
    "def get_spaces(parking_id)->list:\n",
    "    cursorObj = con.cursor()\n",
    "    cursorObj.execute(\n",
    "        f'SELECT id,vertex FROM manageParking_space WHERE parking_id={parking_id}')\n",
    "\n",
    "    return cursorObj.fetchall() # [(5303, '[[854.5, 219.5], [809.5, 202.5], [845.5, 194.5], [890.5, 213.5]]'), ...]\n",
    "\n",
    "\n",
    "def get_space_vacant(space_id)->bool:\n",
    "    cursorObj = con.cursor()\n",
    "    cursorObj.execute(\n",
    "        f'SELECT vacant FROM manageParking_space WHERE id={space_id}')\n",
    "\n",
    "    return cursorObj.fetchall()[0][0]\n",
    "\n",
    "def update_space_occupancy(space_id, is_vacant):\n",
    "    now = datetime.now()\n",
    "    cursorObj = con.cursor()\n",
    "    sql = f'UPDATE manageParking_space SET vacant=\"{1 if is_vacant else 0}\", since=\\\"{now}\\\" WHERE id={space_id}'\n",
    "    res = cursorObj.execute(sql)\n",
    "    con.commit()\n",
    "    \n",
    "        \n",
    "# CAR DETECTION IN ROI\n",
    "def get_roi(img, vertex):\n",
    "# https://stackoverflow.com/questions/15341538/numpy-opencv-2-how-do-i-crop-non-rectangular-region\n",
    "    cols = vertex[:, :, 0].flatten()\n",
    "    rows = vertex[:, :, 1].flatten()\n",
    "\n",
    "    points = list(zip(cols, rows))\n",
    "    row_min = min(rows)\n",
    "    row_max = max(rows)\n",
    "    col_min = min(cols)\n",
    "    col_max = max(cols)\n",
    "\n",
    "    # print(row_min, row_max, col_min, col_max)\n",
    "    mask = np.zeros(img.shape, dtype=np.uint8)\n",
    "    # fill the ROI so it doesn't get wiped out when the mask is applied\n",
    "    cv.fillPoly(mask, [np.array(points)], 255)\n",
    "\n",
    "    # apply the mask\n",
    "    masked_image = cv.bitwise_and(img, mask)\n",
    "\n",
    "    return masked_image[ row_min:row_max,col_min:col_max,]\n",
    "\n",
    "def imhist(src):\n",
    "    bgr_planes = cv.split(src)\n",
    "    histSize = 256\n",
    "    histRange = (0, 256)  # the upper boundary is exclusive\n",
    "    accumulate = False\n",
    "    b_hist = cv.calcHist(bgr_planes, [0], None, [\n",
    "                         histSize], histRange, accumulate=accumulate)\n",
    "    g_hist = cv.calcHist(bgr_planes, [1], None, [\n",
    "                         histSize], histRange, accumulate=accumulate)\n",
    "    r_hist = cv.calcHist(bgr_planes, [2], None, [\n",
    "                         histSize], histRange, accumulate=accumulate)\n",
    "    hist_w = 512\n",
    "    hist_h = 400\n",
    "    bin_w = int(round(hist_w/histSize))\n",
    "    histImage = np.zeros((hist_h, hist_w, 3), dtype=np.uint8)\n",
    "    cv.normalize(b_hist, b_hist, alpha=0, beta=hist_h,\n",
    "                 norm_type=cv.NORM_MINMAX)\n",
    "    cv.normalize(g_hist, g_hist, alpha=0, beta=hist_h,\n",
    "                 norm_type=cv.NORM_MINMAX)\n",
    "    cv.normalize(r_hist, r_hist, alpha=0, beta=hist_h,\n",
    "                 norm_type=cv.NORM_MINMAX)\n",
    "    for i in range(1, histSize):\n",
    "        cv.line(histImage, (bin_w*(i-1), hist_h - int(b_hist[i-1])),\n",
    "                (bin_w*(i), hist_h - int(b_hist[i])),\n",
    "                (255, 0, 0), thickness=2)\n",
    "        cv.line(histImage, (bin_w*(i-1), hist_h - int(g_hist[i-1])),\n",
    "                (bin_w*(i), hist_h - int(g_hist[i])),\n",
    "                (0, 255, 0), thickness=2)\n",
    "        cv.line(histImage, (bin_w*(i-1), hist_h - int(r_hist[i-1])),\n",
    "                (bin_w*(i), hist_h - int(r_hist[i])),\n",
    "                (0, 0, 255), thickness=2)\n",
    "    cv.imshow('Source image', src)\n",
    "    cv.imshow('calcHist Demo', histImage)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "def imshow(img, title=''):\n",
    "    while(1):\n",
    "        cv.imshow(title, img)\n",
    "        if cv.waitKey(20) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "def drawSpaceSeg(img, vertex, count, occupied, col_min, row_max, space_area, real_occupied=None):\n",
    "    if real_occupied is not None:\n",
    "        if not occupied and not real_occupied: # True positive\n",
    "            cv.polylines(img, [vertex], True, (0, 255, 0), thickness=2)\n",
    "        elif occupied and real_occupied: # True negative\n",
    "            cv.polylines(img, [vertex], True, (0, 0, 255), thickness=2)\n",
    "        elif occupied and not real_occupied: # False negative\n",
    "             cv.polylines(img, [vertex], True, (58, 146, 255), thickness=2)\n",
    "        else: # False positive\n",
    "            cv.polylines(img, [vertex], True, (98, 169, 36), thickness=2)\n",
    "    else:\n",
    "        if not occupied:\n",
    "            cv.polylines(img, [vertex], True, (0, 255, 0), thickness=2)\n",
    "        else:\n",
    "            cv.polylines(img, [vertex], True, (0, 0, 255), thickness=2)\n",
    "\n",
    "    # Pixel count\n",
    "    text = str(round(count/space_area,3))\n",
    "    cvzone.putTextRect(img, text, (col_min, row_max-3), scale=0.8, thickness=1, offset=0)\n",
    "    return img\n",
    "\n",
    "def on_trackbar(a):\n",
    "    pass    \n",
    "\n",
    "def bwareaopen(imgOriginal, min_size, connectivity=8):\n",
    "        \"\"\"\n",
    "        https://stackoverflow.com/questions/2348365/matlab-bwareaopen-equivalent-function-in-opencv\n",
    "        Remove small objects from binary image (approximation of \n",
    "        bwareaopen in Matlab for 2D images).\n",
    "    \n",
    "        Args:\n",
    "            img: a binary image (dtype=uint8) to remove small objects from\n",
    "            min_size: minimum size (in pixels) for an object to remain in the image\n",
    "            connectivity: Pixel connectivity; either 4 (connected via edges) or 8 (connected via edges and corners).\n",
    "    \n",
    "        Returns:\n",
    "            the binary image with small objects removed\n",
    "        \"\"\"\n",
    "        img = imgOriginal.copy()\n",
    "        # Find all connected components (called here \"labels\")\n",
    "        num_labels, labels, stats, centroids = cv.connectedComponentsWithStats(\n",
    "            img, connectivity=connectivity)\n",
    "        \n",
    "        # check size of all connected components (area in pixels)\n",
    "        for i in range(num_labels):\n",
    "            label_size = stats[i, cv.CC_STAT_AREA]\n",
    "            \n",
    "            # remove connected components smaller than min_size\n",
    "            if label_size < min_size:\n",
    "                img[labels == i] = 0\n",
    "                \n",
    "        return img\n",
    "\n",
    "# https://stackoverflow.com/questions/451426/how-do-i-calculate-the-area-of-a-2d-polygon\n",
    "def area(p):\n",
    "    return 0.5 * abs(sum(x0*y1 - x1*y0\n",
    "                         for ((x0, y0), (x1, y1)) in segments(p)))\n",
    "\n",
    "def segments(p):\n",
    "    return zip(p, p[1:] + [p[0]])\n",
    "\n",
    "def is_space_vacant(vertex, count, k)->bool:\n",
    "    a = area(vertex)\n",
    "\n",
    "    return(count < k * a)\n",
    "\n",
    "class DetectionParams:\n",
    "    def __init__(self, gb_k, gb_s, at_method, at_blockSize, at_C, median_k=-1, bw_size=-1, bw_conn=8):\n",
    "        self.gb_k = gb_k # GaussianBlur kernel\n",
    "        self.gb_s = gb_s # GaussianBlur sigma (std. deviation)\n",
    "        self.at_method = at_method # adaptiveThreshold method\n",
    "        self.at_blockSize = at_blockSize # adaptiveThreshold blockSizeneighborhood that is used to calculate a threshold value for the pixel\n",
    "        self.at_C = at_C # adaptiveThreshold C constant to be substracted\n",
    "        self.median_k = median_k # Median filter kernel size (-1 if not desired to apply)\n",
    "        self.bw_size = bw_size # bwareaopen remove objects smaller than this size (-1 if not desired to apply)\n",
    "        self.bw_conn = bw_conn # bwareaopen neighborhood connectivity (default 8)\n",
    "\n",
    "# params01 = DetectionParams((5,5), 0, cv.ADAPTIVE_THRESH_GAUSSIAN_C, 27, 7, 3, 85) # \n",
    "params01 = DetectionParams((5,5), 0, cv.ADAPTIVE_THRESH_GAUSSIAN_C, 33, 7, 3, 85) # UPR05\n",
    "#params01 = DetectionParams((5,5), 0, cv.ADAPTIVE_THRESH_GAUSSIAN_C, 29, 16, 3, 25) # UFPR04\n",
    "\n",
    "    \n",
    "def preProcess(img, showImshow=False, params=params01, channel=\"g\"):\n",
    "    # imgGray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    imgHLS = cv.cvtColor(img, cv.COLOR_BGR2HLS)\n",
    "    l = imgHLS[:, :, 1]\n",
    "    imgHSV = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "    v = imgHSV[:, :, 2]\n",
    "    imgGray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # cv.imshow(\"l\", l)\n",
    "    # cv.imshow(\"v\", v)\n",
    "    # cv.imshow(\"imgGray\", imgGray)\n",
    "    # cv.waitKey(0)\n",
    "\n",
    "    if(channel==\"l\"):\n",
    "        imgGray = l\n",
    "    elif(channel==\"v\"):\n",
    "        imgGray = v\n",
    "\n",
    "    if(params.gb_k==None):\n",
    "        imgBlur = imgGray\n",
    "    else:\n",
    "        imgBlur = cv.GaussianBlur(imgGray, params.gb_k, params.gb_s)\n",
    "\n",
    "    imgThreshold = cv.adaptiveThreshold(imgBlur, 255, params.at_method, cv.THRESH_BINARY_INV, params.at_blockSize, params.at_C)\n",
    "    #a,imgThreshold2 = cv.threshold(imgBlur,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "    # cv.imshow(\"IMGTresh\", imgThreshold)\n",
    "\n",
    "    # Remove salt and pepper noise\n",
    "    if(params.median_k != -1):\n",
    "        imgMedian = cv.medianBlur(imgThreshold, 3)\n",
    "        if(showImshow):\n",
    "            cv.imshow(\"IMGBlur\", imgBlur)\n",
    "            cv.imshow(\"IMGTresh\", imgThreshold)\n",
    "            cv.imshow(\"IMGMedian\", imgMedian)\n",
    "\n",
    "    # Make thicker edges\n",
    "    # kernel = np.ones((5,5), np.uint8) \n",
    "    # imgEro = cv.erode(imgMedian, kernel, iterations=1)\n",
    "    # imgDilate = cv.dilate(imgEro, kernel, iterations=1)\n",
    "\n",
    "    # Remove small objects\n",
    "    if(params.bw_size != -1):\n",
    "        imgBw = bwareaopen(imgMedian, 85)\n",
    "        if(showImshow):\n",
    "            cv.imshow(\"imgBw\", imgBw)\n",
    "    # cv.imshow(\"IMG Dilate\", imgDilate)             \n",
    "\n",
    "    return imgBw\n",
    "\n",
    "def setupPreprocess(img):\n",
    "    imgGray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    imgBlur = cv.GaussianBlur(imgGray, (5,5), 0)\n",
    "\n",
    "    cv.namedWindow(\"Trackbars\")\n",
    "    cv.resizeWindow(\"Trackbars\", 640, 240)\n",
    "    cv.createTrackbar(\"Threshold Blocksize\", \"Trackbars\", 25,100, on_trackbar)\n",
    "    cv.createTrackbar(\"Threshold C\", \"Trackbars\", 16,100, on_trackbar)\n",
    "    cv.createTrackbar(\"Threshold BW\", \"Trackbars\", 20,500, on_trackbar)\n",
    "\n",
    "    while True:\n",
    "        blocksize = cv.getTrackbarPos(\"Threshold Blocksize\", \"Trackbars\")\n",
    "        c = cv.getTrackbarPos(\"Threshold C\", \"Trackbars\")\n",
    "        if blocksize%2 == 0 or blocksize ==0:\n",
    "            blocksize = blocksize+1\n",
    "            \n",
    "        imgThreshold = cv.adaptiveThreshold(imgBlur, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV, blocksize, c)\n",
    "        #imgThreshold2 = cv.threshold(imgBlur,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "        imgMedian = cv.medianBlur(imgThreshold, 5)\n",
    "        # imgEro = cv.erode(imgMedian, kernel, iterations=1)\n",
    "        # imgDilate = cv.dilate(imgEro, kernel, iterations=1)\n",
    "\n",
    "        bwThresh = cv.getTrackbarPos(\"Threshold BW\", \"Trackbars\")\n",
    "        imgBw = bwareaopen(imgThreshold, bwThresh)\n",
    "\n",
    "        cv.imshow(\"IMG\", img)\n",
    "        cv.imshow(\"IMGTresh\", imgThreshold)\n",
    "        cv.imshow(\"IMGMedian\", imgMedian)\n",
    "        cv.imshow(\"IMG BW\", imgBw)\n",
    "        # cv.imshow(\"IMG Dilate\", imgDilate)\n",
    "    \n",
    "    \n",
    "        if cv.waitKey(1) == 27:         # wait for ESC key to exit and terminate progra,\n",
    "            cv.destroyAllWindows()\n",
    "            quit()\n",
    "\n",
    "\n",
    "# SPACE DETECTION IN XML\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup # read XML\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def get_points_xml(space):\n",
    "    vertex = []\n",
    "    for p in space.contour.find_all('point'):\n",
    "        vertex.append([p.get('x'), p.get('y')])\n",
    "    return np.array(vertex, dtype=np.int32)\n",
    "\n",
    "def detect_batch(files, params, k=0.3, showConfusionMatrix=True, showImshow=False, setup=False, channel=\"g\"):\n",
    "\n",
    "    predicted = []\n",
    "    real = []\n",
    "\n",
    "    n_files = len(files)\n",
    "    for idx, filename in enumerate(files):\n",
    "        clear_output(wait=True)\n",
    "        print(f\"{idx+1}/{n_files}: \",filename)\n",
    "        # SPACE OCCUPATION DETECTION \n",
    "        parking_img = cv.imread(filename)\n",
    "        img = parking_img\n",
    "\n",
    "        if(setup):\n",
    "            setupPreprocess(img)\n",
    "        imgPre = preProcess(img, showImshow, params, channel)\n",
    "\n",
    "        # Get spaces from xml\n",
    "        with open( filename.replace('.jpg','.xml'), 'r') as f:\n",
    "            file = f.read()\n",
    "        data = BeautifulSoup(file, \"xml\")\n",
    "        spaces = data.find_all('space')\n",
    "                \n",
    "\n",
    "        for space in spaces:\n",
    "            vertex = get_points_xml(space)\n",
    "            if(vertex.size==0): continue\n",
    "            vertex = vertex.reshape(-1, 1, 2)\n",
    "\n",
    "            cols = vertex[:, :, 0].flatten()\n",
    "            rows = vertex[:, :, 1].flatten()\n",
    "            points = list(zip(cols, rows))\n",
    "            roi = get_roi(imgPre, vertex)\n",
    "            \n",
    "            # cv.imshow(\"roi\", roi)\n",
    "\n",
    "            # Count pixels with value '1'\n",
    "            count = cv.countNonZero(roi)\n",
    "            \n",
    "            # drawSpaceSeg(img, vertex, count)\n",
    "            vacant = is_space_vacant(points, count, k) # Depending on the detection area \n",
    "\n",
    "            vacant_real = space.get('occupied') == \"0\"\n",
    "            predicted.append(vacant)\n",
    "            real.append(vacant_real)\n",
    "\n",
    "            if(showImshow):\n",
    "                space_area = area(points)\n",
    "                assert(space_area > 0)\n",
    "                drawSpaceSeg(img, np.array(points, np.int32), count, not vacant, min(cols), max(rows), space_area, not vacant_real)\n",
    "                if(vacant!=vacant_real): # Show error in prediction\n",
    "                    print(\"ERROR PREDICTED vacant: \"+str(bool(vacant)))\n",
    "                    print(\"Pixel count: \"+str(count))\n",
    "                    print(f\"Area: {space_area} k={count/space_area}\")\n",
    "                    print(\"---------------------------------\")\n",
    "                    cv.namedWindow(\"roi\")\n",
    "                    cv.destroyWindow(\"roi\")\n",
    "                    cv.imshow(\"roi\", roi)\n",
    "                    cv.imshow(\"IMG with space seg\",img)\n",
    "                    cv.waitKey()\n",
    "            \n",
    "        if(showImshow):\n",
    "            cv.imshow(\"IMG with space seg\",img)\n",
    "            key = cv.waitKey()\n",
    "            if(key==27):\n",
    "                break\n",
    "\n",
    "\n",
    "    if(showConfusionMatrix):\n",
    "        confusion_matrix = metrics.confusion_matrix(real, predicted)\n",
    "\n",
    "        #Precision Score = TP / (FP + TP). Minimize FP\n",
    "        print('Precision: %.3f' % metrics.precision_score(real, predicted))\n",
    "        #Recall Score = TP / (FN + TP). Minimize FN\n",
    "        print('Recall: %.3f' % metrics.recall_score(real, predicted))\n",
    "        #F1 Score = 2* Precision Score * Recall Score/ (Precision Score + Recall Score/) . Minimize FN over minimizing FP\n",
    "        print('F1 Score: %.3f' % metrics.f1_score(real, predicted))\n",
    "        #Accuracy Score = (TP + TN)/ (TP + FN + TN + FP) \n",
    "        print('Accuracy: %.3f' % metrics.accuracy_score(real, predicted))\n",
    "\n",
    "        cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['Occupied', 'Vacant']) \n",
    "        cm_display.plot()\n",
    "        plt.show()\n",
    "\n",
    "    if(showImshow):\n",
    "        cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 ('VisionParkDetectEnv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "751c3e3c5f8bc6a4e4e068bb230f26d845892c4443aea059e9acc5405f3faaee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
